{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93e8b151-4c3b-4f1a-b796-aab264b79d07",
   "metadata": {},
   "source": [
    "### Introduction <br>\n",
    "In this project, our goal is to build a predictive model using the MLPClassifier (Multi-layer Perceptron Classifier), a type of neural network, to solve a binary classification problem. The dataset we’re working with contains both numerical and categorical features, which add some complexity to our preprocessing steps. Additionally, there are missing values in several columns, so careful data cleaning is needed to ensure the model has quality input data.\n",
    "\n",
    "My approach involves several key steps:\n",
    "\n",
    "Data Cleaning: We’ll start by handling missing values—removing rows and columns with excessive missing data, then imputing the remaining gaps based on the nature of each feature.<br>\n",
    "Feature Transformation: To prepare our features for the neural network, we need to apply transformations. This includes standardizing numerical features (scaling them to have a mean of 0 and a standard deviation of 1) and encoding categorical features as numbers, which neural networks can process effectively.<br>\n",
    "Model Building: Once our data is ready, we’ll use the MLPClassifier to create a model. This classifier is particularly suited for complex patterns and relationships in data, which makes it an interesting choice for this task.<br>\n",
    "Hyperparameter Tuning: Finally, we’ll optimize the model by experimenting with different hyperparameters (settings like the number of neurons and activation functions). This tuning process helps us find the best configuration to improve the model’s accuracy and ensure it generalizes well to new data.<br>\n",
    "The end goal is to create a model that can make accurate predictions on this dataset, understanding how different preprocessing and tuning decisions impact its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87bbe581-8541-4c2a-bd34-1dc00ba6977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"/Users/kushalreddy/Desktop/option1_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78baad5c-5927-493c-8edb-35be5948a638",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9b81d-63f4-4ec6-881a-946e95b514a7",
   "metadata": {},
   "source": [
    "#### This section outlines the data preparation, model building, and tuning steps undertaken to develop a robust MLP model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c9b3c9-8222-44df-bc4d-e91789e93699",
   "metadata": {},
   "source": [
    "Step 2.1: Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4ce30e2-7f72-44d1-9bc1-981fe34d8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Handle missing values\n",
    "# Drop rows with more than 2 missing values\n",
    "missing_values_per_row = data.isnull().sum(axis=1)\n",
    "rows_to_drop = missing_values_per_row[missing_values_per_row > 2].index\n",
    "data.drop(index=rows_to_drop, inplace=True)\n",
    "\n",
    "# Define numeric and categorical columns\n",
    "numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns.drop('target')\n",
    "categorical_cols = ['category']  # Add more categorical columns here if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd2e029-5eea-441e-b502-88e346016ccc",
   "metadata": {},
   "source": [
    "Step 2.2: Define Numeric and Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c65d87e-d12f-462b-b072-0291643e593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define preprocessing for numerical and categorical columns\n",
    "# Numerical columns: Impute missing values and standardize\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100561fd-1869-44ce-ae78-29604c805f15",
   "metadata": {},
   "source": [
    "Step 2.3: Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a03a8b2-9828-42a3-b887-9d5aea4b9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns: One-hot encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5171de5b-7050-4b18-9598-2cf8c48a4573",
   "metadata": {},
   "source": [
    "Explanation: We use MLPClassifier as our model and set up a pipeline that integrates preprocessing, SMOTE for handling class imbalance, and the classifier. This setup ensures streamlined and consistent application of each step across data splits.\n",
    "\n",
    "We use SMOTE (Synthetic Minority Over-sampling Technique) to handle class imbalance by generating synthetic samples for the minority class. This helps the model learn patterns in both classes without becoming biased toward the majority class, leading to a fairer and more accurate model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "357311f4-9a8f-4e8d-bc9f-0e089180bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define MLPClassifier and create a pipeline with preprocessing and classifier\n",
    "mlp = MLPClassifier(max_iter=500, random_state=42)\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),  # SMOTE added within pipeline for balancing\n",
    "    ('classifier', mlp)\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "    'classifier__activation': ['relu', 'tanh'],\n",
    "    'classifier__solver': ['adam', 'sgd']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bece9f-a8ef-43e6-8118-11de7315d686",
   "metadata": {},
   "source": [
    "Step 3: Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d2310a7-8eda-436b-8c5e-9c5e82a89fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Split the data into training and testing sets\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0356086e-30b9-4571-89df-11e7ac6b203a",
   "metadata": {},
   "source": [
    "Step 4: Hyperparameter Tuning and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c5f9c5d8-a76b-4aa5-8065-7f0e7af9e365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from GridSearchCV: {'classifier__activation': 'tanh', 'classifier__hidden_layer_sizes': (100,), 'classifier__solver': 'adam'}\n",
      "Best Score from GridSearchCV: 0.8833333333333332\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Perform hyperparameter tuning with GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score from the grid search\n",
    "print(\"Best Parameters from GridSearchCV:\", grid_search.best_params_)\n",
    "print(\"Best Score from GridSearchCV:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c43e7a6-1c81-4937-8fd8-8c6cc9256afb",
   "metadata": {},
   "source": [
    "Step 5: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0ff6b514-0dca-4f66-800a-b4e6a7a51992",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = grid_search.best_estimator_\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "\n",
    "# Calculate Evaluation Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='binary')\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686971a-1bcb-4f24-95a1-8dfe993623c1",
   "metadata": {},
   "source": [
    "Evaluation:\n",
    "\n",
    "Accuracy: 83.0% of predictions were correct, showing solid overall performance. <br>\n",
    "Precision: 78.1% precision indicates that of the cases the model labeled as positive, about 78.1% were correct, which is reasonable for tasks where we want to avoid false positives.<br>\n",
    "Recall: The recall of 80.0% shows the model captured 80% of actual positive cases, striking a good balance between sensitivity and avoiding false negatives.<br>\n",
    "F1 Score: An F1 score of 79.0% balances precision and recall, indicating strong performance.<br>\n",
    "**Confusion Matrix:**\n",
    "True Positives (64): Correct positive predictions.<br>\n",
    "True Negatives (102): Correct negative predictions.<br>\n",
    "False Positives (18): Instances incorrectly classified as positive.<br>\n",
    "False Negatives (16): Missed positive instances.<br>\n",
    "The model handles both false positives and false negatives reasonably well, making it suitable for applications where balanced error rates are needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f6cb3-2e42-4dbd-9aa2-9b31a0b9d1b4",
   "metadata": {},
   "source": [
    "Step 6: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3a2c6280-025e-4d88-8992-ab3557699828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9056\n",
      "Test Precision: 0.8537\n",
      "Test Recall: 0.9333\n",
      "Test F1 Score: 0.8917\n",
      "Confusion Matrix:\n",
      " [[93 12]\n",
      " [ 5 70]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e296e0-49e5-4844-bd88-ba42e43ca4af",
   "metadata": {},
   "source": [
    "\n",
    "### Conclusion:\n",
    "The model achieves a solid performance with an 83% accuracy, effectively balancing precision (78.1%) and recall (80%). This suggests the model reliably identifies true positives while keeping false positives and false negatives reasonably low. With an F1 score of 79%, it handles both types of errors well, making it suitable for scenarios where both precision and recall are important. The confusion matrix (64 true positives, 102 true negatives, 18 false positives, and 16 false negatives) indicates that the model is fairly accurate, but adjustments could be made depending on whether minimizing false positives or maximizing recall is prioritized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d90022-b478-4a46-a2fd-80f033ff331e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
